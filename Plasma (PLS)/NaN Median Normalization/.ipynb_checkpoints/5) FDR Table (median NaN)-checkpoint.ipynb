{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068de027-b9f6-4107-bc24-44332063ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d060e39a-987f-4dff-b77f-00b4a7268f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metacor(r, n, do_fisher=True, return_transformed=True, cor_type=\"pearson\", meta_type=\"fixed\"):\n",
    " if cor_type not in [\"pearson\", \"spearman\"]:\n",
    "  raise Exception(f\"Invalid correlation type \\\"{cor_type}\\\"\")\n",
    " if meta_type not in [\"fixed\", \"random\"]:\n",
    "  raise Exception(f\"Invalid meta analysis type \\\"{meta_type}\\\"\")\n",
    "\n",
    " if not do_fisher:\n",
    "  raise Exception(\"Non-Fisher's-z-transformed correlations not yet supported\")\n",
    " if meta_type == \"random\":\n",
    "  raise Exception(\"Random effects meta analysis not yet supported\")\n",
    " if not return_transformed:\n",
    "  raise Exception(\"Returning an untransformed common correlation coefficient estimate not yet supported\")\n",
    "\n",
    " do_override = False\n",
    "\n",
    " if do_fisher:\n",
    "  # Explicitly handle cases of r = 1 or r = -1\n",
    "  r_p_one = (r == 1.0).any(axis=1)\n",
    "  r_n_one = (r == -1.0).any(axis=1)\n",
    "  override = (r_p_one | r_n_one)\n",
    "  do_override = np.any(override)\n",
    "  if do_override:\n",
    "   # r_common = inf or -inf depending on sign of r\n",
    "   r_common_override_val = np.where(r_p_one, np.inf, np.where(r_n_one, -np.inf, np.nan))\n",
    "   # p = 0\n",
    "   p_override_val = np.where(override, 0.0, np.nan)\n",
    "\n",
    "   # Convert `override` to a column of a matrix, then broadcast to match `r`\n",
    "   # Needs to be done explicitly, as otherwise `where` could broadcast `override` along rows instead of columns\n",
    "   override_matrix = np.broadcast_to(np.reshape(override, (-1, 1)), r.shape)\n",
    "   r = np.where(override_matrix, np.nan, r)\n",
    "   n = np.where(override_matrix, np.nan, n)\n",
    "\n",
    "  r = np.arctanh(r)\n",
    "\n",
    " if cor_type == \"pearson\":\n",
    "  if do_fisher:\n",
    "   # Bonett (2000); DOI: 10.1007/BF02294183\n",
    "   variance = 1 / (n - 3)\n",
    "  else:\n",
    "   raise Exception(\"NYI\")\n",
    " elif cor_type == \"spearman\":\n",
    "  if do_fisher:\n",
    "   # Bonett (2000); DOI: 10.1007/BF02294183\n",
    "   variance = (1 + (np.square(r) / 2)) / (n - 3)\n",
    "  else:\n",
    "   raise Exception(\"NYI\")\n",
    "\n",
    " # Cooper (2009); ISBN: 978-0-87154-163-5\n",
    " weight = 1 / variance\n",
    " variance_common = 1 / np.nansum(weight, axis=1)\n",
    " r_common = np.nansum(np.multiply(weight, r), axis=1) * variance_common\n",
    "\n",
    " stddev_common = np.sqrt(variance_common)\n",
    " z = r_common / stddev_common\n",
    " p = 2 * scipy.stats.norm.sf(np.abs(z))\n",
    "\n",
    " if do_override:\n",
    "  r_common = np.where(override, r_common_override_val, r_common)\n",
    "  p = np.where(override, p_override_val, p)  \n",
    "\n",
    " return r_common, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c8c921-bcab-4223-9518-d54a572e33bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/ndw_qsrd5cbch1pd347wrwx40000gn/T/ipykernel_7563/3077440499.py:51: RuntimeWarning: divide by zero encountered in divide\n",
      "  variance_common = 1 / np.nansum(weight, axis=1)\n",
      "/var/folders/0q/ndw_qsrd5cbch1pd347wrwx40000gn/T/ipykernel_7563/3077440499.py:52: RuntimeWarning: invalid value encountered in multiply\n",
      "  r_common = np.nansum(np.multiply(weight, r), axis=1) * variance_common\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FDR Meta-analysis + FDR Table.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# Load CSVs\n",
    "vecpac = pd.read_csv(\"3. Metabolite Pairs/COMBINATIONS_pls_VECPAC.csv\")\n",
    "lps    = pd.read_csv(\"3. Metabolite Pairs/COMBINATIONS_pls_LPS.csv\")\n",
    "dss    = pd.read_csv(\"3. Metabolite Pairs/COMBINATIONS_pls_DSS.csv\")\n",
    "#print(lps)\n",
    "# Rename correlation & p-value columns\n",
    "vecpac.columns.values[2] = 'VECPAC r'\n",
    "vecpac.columns.values[3] = 'VECPAC p-values'\n",
    "lps.columns.values[2]    = 'LPS r'\n",
    "lps.columns.values[3]    = 'LPS p-values'\n",
    "dss.columns.values[2]    = 'DSS r'\n",
    "dss.columns.values[3]    = 'DSS p-values'\n",
    "\n",
    "# Select only DSS r/p-values and LPS r/p-values\n",
    "dss_subset = dss[['DSS r', 'DSS p-values']]\n",
    "lps_subset = lps[['LPS r', 'LPS p-values']]\n",
    "\n",
    "#print(vecpac)\n",
    "#print(dss_subset)\n",
    "#print(lps_subset)# \n",
    "#vecpac.to_csv(\"VECPAC_only.csv\", index=False)\n",
    "#dss_subset.to_csv(\"DSS_only.csv\", index=False)\n",
    "#lps_subset.to_csv(\"LPS_only.csv\", index=False)\n",
    "#print(\"Saved individual CSVs: VECPAC_only.csv, DSS_only.csv, LPS_only.csv\")\n",
    "\n",
    "\n",
    "# Concatenate columns\n",
    "df = pd.concat([vecpac, dss_subset, lps_subset], axis=1)\n",
    "\n",
    "# Add a new column based on sign consistency\n",
    "df['Consistent?'] = (\n",
    "    ((df['VECPAC r'] > 0) & (df['LPS r'] > 0) & (df['DSS r'] > 0)) |\n",
    "    ((df['VECPAC r'] < 0) & (df['LPS r'] < 0) & (df['DSS r'] < 0))\n",
    ")\n",
    "\n",
    "is_consistent = df['Can Meta-Analysis Be Calculated?'] = (\n",
    "    ((((df['VECPAC r'] > 0) | pd.isna(df['VECPAC r'])) &\n",
    "        ((df['LPS r'] > 0) | pd.isna(df['LPS r'])) &\n",
    "        ((df['DSS r'] > 0) | pd.isna(df['DSS r']))) |\n",
    "    (((df['VECPAC r'] < 0) | pd.isna(df['VECPAC r'])) &\n",
    "        ((df['LPS r'] < 0) | pd.isna(df['LPS r'])) &\n",
    "        ((df['DSS r'] < 0) | pd.isna(df['DSS r']))))\n",
    "    &\n",
    "    (df[['VECPAC r', 'LPS r', 'DSS r']].isna().sum(axis=1) <= 1)\n",
    ")\n",
    "\n",
    "\n",
    "# Filter rows where Consistent? == True\n",
    "#is_consistent = df['Can Meta-Analysis Be Calculated?'] == True\n",
    "df_consistent = df.loc[is_consistent].copy()\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "# Extract correlation columns (3rd, 5th, 7th columns) --> (VECPAC r, DSS r, LPS r)\n",
    "r = df_consistent.iloc[:, [2, 4, 6]].to_numpy()\n",
    "#print(r[50095,:])\n",
    "\n",
    "# Sample size matrix, same shape/size as r\n",
    "num_rows = r.shape[0]\n",
    "n = np.tile([19, 13, 7], (num_rows, 1))  # Adjust based on sample size per group\n",
    "\n",
    "# Run meta-analysis\n",
    "r_common, p_values = metacor(r, n, do_fisher=True, cor_type=\"spearman\", meta_type=\"fixed\")\n",
    "\n",
    "## Add raw p-values and r-values only to the consistent (non-NaN) subset\n",
    "#df_consistent_nonan = df_consistent.dropna(subset=['VECPAC r', 'DSS r', 'LPS r']).copy()\n",
    "#df_consistent_nonan['Meta-Analysis r'] = r_common\n",
    "#df_consistent_nonan['Meta-Analysis p-value'] = p_values\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "# Add raw p-values column only to consistent metabolites\n",
    "df_consistent['Meta-Analysis p-value'] = p_values\n",
    "# Add meta-analysis values into original table\n",
    "df['Meta-Analysis p-value'] = np.nan\n",
    "df.loc[is_consistent, 'Meta-Analysis p-value'] = p_values\n",
    "\n",
    "# Run FDR correction only on valid p-values\n",
    "is_valid = ~df['Meta-Analysis p-value'].isna()\n",
    "rejected, pvals_corrected = fdrcorrection(df.loc[is_valid, 'Meta-Analysis p-value'], alpha=0.05, method='indep',is_sorted=False)\n",
    "\n",
    "# Add FDR results\n",
    "df['FDR'] = np.nan\n",
    "df.loc[is_valid, 'FDR'] = pvals_corrected\n",
    "\n",
    "# Save final file\n",
    "fdr_file = \"Meta-analysis + FDR Table.csv\"\n",
    "df.to_csv(fdr_file, index=False)\n",
    "print(\"Saved FDR\", fdr_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72598b-b56f-44fc-8208-14ae0c21cf27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
